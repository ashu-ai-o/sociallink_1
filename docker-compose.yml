// ==============================================================================
// DEPLOYMENT GUIDE - docker-compose.yml
// ==============================================================================

/*
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=linkplease_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=yourpassword
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-EXEC", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for Channels, Cache, Celery
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes

  # Django + Channels (ASGI with Daphne)
  web:
    build: .
    command: daphne -b 0.0.0.0 -p 8000 linkplease.asgi:application
    volumes:
      - .:/app
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:yourpassword@postgres:5432/linkplease_db
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
    depends_on:
      - postgres
      - redis
    deploy:
      replicas: 3  # 3 instances for load balancing
      resources:
        limits:
          cpus: '2'
          memory: 2G

  # Celery Workers (Background Tasks)
  celery_worker:
    build: .
    command: celery -A linkplease worker --loglevel=info --concurrency=10 -P gevent
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgresql://postgres:yourpassword@postgres:5432/linkplease_db
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
    depends_on:
      - postgres
      - redis
    deploy:
      replicas: 5  # 5 worker instances for parallel processing
      resources:
        limits:
          cpus: '2'
          memory: 2G

  # Celery Beat (Scheduler)
  celery_beat:
    build: .
    command: celery -A linkplease beat --loglevel=info
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgresql://postgres:yourpassword@postgres:5432/linkplease_db
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
    depends_on:
      - postgres
      - redis

  # Nginx Load Balancer
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - web

volumes:
  postgres_data:
  redis_data:
*/




// ==============================================================================
// Dockerfile - Multi-stage Build
// ==============================================================================

/*
FROM python:3.11-slim as base

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Run migrations and collect static
RUN python manage.py collectstatic --noinput

EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/health/')"
*/


// ==============================================================================
// nginx.conf - Load Balancer Configuration
// ==============================================================================

/*
upstream django_backend {
    least_conn;  # Load balancing method
    server web:8000 max_fails=3 fail_timeout=30s;
}

upstream websocket_backend {
    ip_hash;  # Sticky sessions for WebSockets
    server web:8000;
}

server {
    listen 80;
    server_name linkplease.co;

    client_max_body_size 10M;

    # HTTP to HTTPS redirect
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name linkplease.co;

    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;

    # WebSocket connections
    location /ws/ {
        proxy_pass http://websocket_backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket timeout
        proxy_read_timeout 86400;
        proxy_send_timeout 86400;
    }

    # Regular HTTP requests
    location / {
        proxy_pass http://django_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # Static files
    location /static/ {
        alias /app/staticfiles/;
        expires 30d;
        add_header Cache-Control "public, immutable";
    }
}
*/


// ==============================================================================
// DEPLOYMENT COMMANDS
// ==============================================================================

/*
# 1. Build and start all services
docker-compose up -d --build --scale celery_worker=5 --scale web=3

# 2. Run migrations
docker-compose exec web python manage.py migrate

# 3. Create superuser
docker-compose exec web python manage.py createsuperuser

# 4. Monitor logs
docker-compose logs -f web celery_worker

# 5. Check status
docker-compose ps

# 6. Scale services
docker-compose up -d --scale celery_worker=10  # 10 workers
docker-compose up -d --scale web=5  # 5 web instances

# 7. Monitor Redis connections
docker-compose exec redis redis-cli INFO clients

# 8. Monitor Celery tasks
docker-compose exec celery_worker celery -A linkplease inspect active

# PRODUCTION SCALING FOR 10K+ USERS:
# - 5-10 web instances (ASGI/Daphne)
# - 10-20 Celery workers
# - Redis cluster (3 nodes minimum)
# - PostgreSQL with read replicas
# - Nginx with SSL termination
*/


// ==============================================================================
// PERFORMANCE MONITORING - Prometheus + Grafana
// ==============================================================================

/*
# Add to docker-compose.yml:

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
*/

// ==============================================================================
// PRODUCTION CHECKLIST
// ==============================================================================

/*
✅ INFRASTRUCTURE:
- [ ] Multi-instance deployment (3+ web, 5+ workers)
- [ ] Redis cluster for high availability
- [ ] PostgreSQL with connection pooling
- [ ] Nginx load balancer with SSL
- [ ] Health checks and auto-restart

✅ PERFORMANCE:
- [ ] Database indexes on frequent queries
- [ ] Redis caching for rate limiting
- [ ] Connection pooling (DB + HTTP)
- [ ] Async I/O throughout
- [ ] Gevent/uvloop for concurrency

✅ MONITORING:
- [ ] Prometheus for metrics
- [ ] Grafana for visualization
- [ ] Sentry for error tracking
- [ ] WebSocket connection monitoring
- [ ] Celery task monitoring

✅ SECURITY:
- [ ] SSL/TLS certificates
- [ ] Rate limiting per user
- [ ] CORS configuration
- [ ] Environment variables for secrets
- [ ] Regular security updates

✅ SCALABILITY:
- [ ] Horizontal scaling ready
- [ ] Stateless application design
- [ ] Redis for session storage
- [ ] CDN for static files
- [ ] Database read replicas
*/